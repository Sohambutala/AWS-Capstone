{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6841a2c-e2b4-4724-989c-fdba9a8c1acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pygam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c70a9d-ec20-4268-b3d7-44a81686d6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from pygam import LinearGAM, s, f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3186804d-ac05-4320-ad72-1a9ff3b7ffa8",
   "metadata": {},
   "source": [
    "# Data Loading and Merging\n",
    "Loading all CSV files generated from Data Extraction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f580fc-e178-48b9-bb79-b7a8897c5ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates = [\n",
    "'2022-01-31',\n",
    "'2022-02-28',\n",
    "'2022-03-31',\n",
    "'2022-04-30',\n",
    "'2022-05-31',\n",
    "'2022-06-30',\n",
    "'2022-07-31',\n",
    "'2022-08-31',\n",
    "'2022-09-30',\n",
    "'2022-10-31',\n",
    "'2022-11-30',\n",
    "'2022-12-31'\n",
    "]\n",
    "\n",
    "s3dfs = []\n",
    "for index in tqdm(range(0, len(dates), 1), desc=\"Processing dates\"):\n",
    "    df = pd.read_csv(f'./traffic_data/traffic_data_{dates[index]}.csv')\n",
    "    s3dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0c96a-895f-40bf-9706-fb16d5eb41fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3df = pd.concat(s3dfs, ignore_index = True)\n",
    "s3df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589ccfb-8f6b-4279-9c4c-ed57d4123f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(s3df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2690a9-4c50-41e6-8bcd-98e14ca89bba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e4e41-d230-4099-9e94-8e2841573257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting datetime to date\n",
    "s3df['datetime'] = pd.to_datetime(s3df['datetime'])\n",
    "s3df['datetime'] = s3df['datetime'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95440c17-40f3-498c-a1d6-7c17aa9f8716",
   "metadata": {},
   "source": [
    "# Data Aggregation\n",
    "The goal is to group the data by `container_group`, `datetime`, and `disk_capacity_tb` to understand the distribution and count of `chunk_id` over different periods and configurations. This would give us the number of transactions which were recorded in the past and later can be used for predicting future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559005a0-d39e-47f9-ae9a-4802780e7fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3df_agg = s3df.groupby(['container_group', 'datetime', 'disk_capacity_tb'])['chunk_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bdd5f-18e3-4322-8484-cb3f50cb7aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = s3df_agg.reset_index(name='count')\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa21dcb-a259-4dfc-9322-c695d371aa92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52c7df-9322-4cd7-b841-ae802dba8dc6",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1417b-01f0-4300-84a2-809f6cd63933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Univariate Analysis: Histograms for numerical features\n",
    "df.hist(bins=15, figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "# Bivariate Analysis: Scatter plots for numerical features against the target variable\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "for column in numeric_columns:\n",
    "    if column != 'count':\n",
    "        df.plot(kind='scatter', x=column, y='count')\n",
    "        plt.show()\n",
    "        \n",
    "plt.plot(df['datetime'], df['count'], 'o', color='black')\n",
    "\n",
    "\n",
    "# Outlier Detection using IQR\n",
    "Q1 = df[numeric_columns].quantile(0.25)\n",
    "Q3 = df[numeric_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outlier_condition = (df[numeric_columns] < (Q1 - 1.5 * IQR)) | (df[numeric_columns] > (Q3 + 1.5 * IQR))\n",
    "outliers = df[outlier_condition.any(axis=1)]\n",
    "print(f\"Number of outliers detected: {outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8685069-75e8-4503-a3e7-ab253b218c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using boxplot to visualize outliers\n",
    "sns.boxplot(x=df['count'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9689a-e6c7-478f-b5a9-85a294d1963f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataModel:\n",
    "    def __init__(self, model_type='xgboost'):\n",
    "        self.model_type = model_type\n",
    "        if model_type == 'random_forest':\n",
    "            self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'lasso':\n",
    "            self.model = make_pipeline(StandardScaler(), Lasso(alpha=0.1, random_state=42))\n",
    "        elif model_type == 'gam':\n",
    "            self.model = LinearGAM()\n",
    "        else:\n",
    "            self.model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        xdf = df.copy(deep=True)\n",
    "        xdf = xdf.sort_values(by=['container_group', 'disk_capacity_tb', 'datetime'])\n",
    "        \n",
    "        # Encoding container_group\n",
    "        xdf['container_group_encoded'] = self.label_encoder.fit_transform(xdf['container_group'])\n",
    "\n",
    "        if self.model_type == 'gam':\n",
    "            xdf['timestamp'] = xdf['datetime'].apply(lambda x: x.timestamp())\n",
    "\n",
    "        # Extracting datetime features\n",
    "        xdf['month'] = xdf['datetime'].dt.month\n",
    "        xdf['day'] = xdf['datetime'].dt.day\n",
    "\n",
    "        # Cyclical encoding of day and month\n",
    "        xdf['day_sin'] = np.sin(xdf['day'] * (2. * np.pi / xdf['day'].max()))\n",
    "        xdf['day_cos'] = np.cos(xdf['day'] * (2. * np.pi / xdf['day'].max()))\n",
    "        xdf['month_sin'] = np.sin((xdf['month'] - 1) * (2. * np.pi / 12))\n",
    "        xdf['month_cos'] = np.cos((xdf['month'] - 1) * (2. * np.pi / 12))\n",
    "\n",
    "        # Dropping original columns\n",
    "        xdf.drop(['datetime', 'container_group'], axis=1, inplace=True)\n",
    "\n",
    "        # Remove outliers\n",
    "        z = np.abs(stats.zscore(xdf['count']))\n",
    "        xdf = xdf[(z < 3)]\n",
    "\n",
    "        # Create lagged features (shift the target variable 'y' back one time step)\n",
    "        # xdf['y_lagged'] = xdf['count'].shift(1)\n",
    "\n",
    "        # Create a rolling window feature (calculate the rolling mean of 'y' over the past 3 time steps)\n",
    "        # xdf['y_rolling_mean'] = xdf['count'].rolling(window=3).mean()\n",
    "        \n",
    "        return xdf.dropna()\n",
    "\n",
    "    def train(self, df):\n",
    "        xdf = self.preprocess(df)\n",
    "        X = xdf.drop('count', axis=1)\n",
    "        y = xdf['count']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=9)\n",
    "        \n",
    "        if self.model_type == 'gam':\n",
    "            self.model.gridsearch(X_train.values, y_train.values)\n",
    "        else:    \n",
    "            self.model.fit(X_train, y_train)\n",
    "\n",
    "        # Model evaluation\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Mean Absolute Error (MAE): {mae}')\n",
    "        print(f'Mean Squared Error (MSE): {mse}')\n",
    "        print(f'Mean Absolute Percentage Error (MAPE): {mape}%')\n",
    "        print(f'R-squared (R2): {r2}')\n",
    "\n",
    "    def predict(self, day, month, disk_capacity, container_group):\n",
    "        container_group_encoded = self.label_encoder.transform([container_group])[0]\n",
    "        # Prepare input for prediction\n",
    "        sample_input = pd.DataFrame({\n",
    "            'disk_capacity_tb': [disk_capacity],\n",
    "            'container_group_encoded': [container_group_encoded],\n",
    "            'month': [month],\n",
    "            'day': [day],\n",
    "            'day_sin': [np.sin(day * (2. * np.pi / 31))],\n",
    "            'day_cos': [np.cos(day * (2. * np.pi / 31))],\n",
    "            'month_sin': [np.sin((month - 1) * (2. * np.pi / 12))],\n",
    "            'month_cos': [np.cos((month - 1) * (2. * np.pi / 12))]\n",
    "        })\n",
    "\n",
    "        return int(self.model.predict(sample_input)[0])\n",
    "\n",
    "    def save_model(self, filename='SamplePredictor.pickle'):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c97ba-6478-43f2-9bad-ba27aab7f801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('XGBoost')\n",
    "xg_data_model = DataModel(model_type='xgboost')\n",
    "xg_data_model.train(df)\n",
    "\n",
    "print('\\n\\nRandom Forest')\n",
    "rf_data_model = DataModel(model_type='random_forest')\n",
    "rf_data_model.train(df)\n",
    "\n",
    "print('\\n\\nLasso')\n",
    "l_data_model = DataModel(model_type='lasso')\n",
    "l_data_model.train(df)\n",
    "\n",
    "print('\\n\\nGAM')\n",
    "gam_data_model = DataModel(model_type='gam')\n",
    "gam_data_model.train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6980a-76cb-4d33-853c-0e330e5f3ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "day = 15\n",
    "month = 7\n",
    "disk_capacity = 20\n",
    "container_group = '02892102A8F17B5A551466B444222F4C3D9A399F'\n",
    "print(f'For sample input day : {day}, month : {month}, disk capacity : {disk_capacity}, container group : {container_group}') \n",
    "print(rf_data_model.predict(day=day, month=month, disk_capacity=disk_capacity, container_group=container_group))\n",
    "\n",
    "rf_data_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5b31a-d095-47f6-bbcb-7a19ba76c078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(rf_data_model.predict(day=1, month=1, disk_capacity=16, container_group='02892102A8F17B5A551466B444222F4C3D9A399F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4599a79d-f4f6-4c8c-bfc5-46eda129e8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(xg_data_model.predict(day=1, month=1, disk_capacity=16, container_group='02892102A8F17B5A551466B444222F4C3D9A399F'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00876b20-393a-45c7-8a57-9c0225d2ad46",
   "metadata": {},
   "source": [
    "# Time Series Analysis : Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5b722-43fb-4d18-b680-73a5049b4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75734b0a-fa68-4954-b762-49086a4a42bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc855002-2b38-4ea9-9099-12c9e6162ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = df.copy(deep=True)\n",
    "pdf.rename(columns={'datetime': 'ds', 'count': 'y'}, inplace=True)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "categorical_features = encoder.fit_transform(pdf[['container_group', 'disk_capacity_tb']])\n",
    "categorical_features_df = pd.DataFrame(categorical_features.toarray(), columns=encoder.get_feature_names_out(['container_group', 'disk_capacity_tb']))\n",
    "\n",
    "pdf = pdf.join(categorical_features_df)\n",
    "\n",
    "pdf.drop(['container_group', 'disk_capacity_tb'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e3038-3136-428d-885d-6b411c336da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff_date = '2022-11-01'\n",
    "train_df = pdf[pdf['ds'] < cutoff_date]\n",
    "test_df = pdf[pdf['ds'] >= cutoff_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e26682-5648-4817-b9f2-751767df17b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "\n",
    "for column in categorical_features_df.columns:\n",
    "    m.add_regressor(column)\n",
    "\n",
    "m.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80d5d3-0d75-4a42-8c7e-c29d52e54d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "future_dates = m.make_future_dataframe(periods=test_df.shape[0])\n",
    "\n",
    "test_df_prepared = test_df[['ds'] + list(categorical_features_df.columns)]\n",
    "\n",
    "forecast = m.predict(test_df_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c81502-8bc6-4617-9eed-476746fde3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig1 = m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a49c30-3ef3-4e44-bd40-2181e75db211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_test_df = test_df[['ds', 'y']]\n",
    "forecast_df = forecast[['ds', 'yhat']]\n",
    "temp_test_df['yhat'] = forecast['yhat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959ebf9-5698-4730-943a-4468ae408f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate MSE\n",
    "mse = mean_squared_error(temp_test_df['y'], temp_test_df['yhat'])\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(temp_test_df['y'], temp_test_df['yhat'])\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# Calculate MAPE\n",
    "mape = np.mean(np.abs((temp_test_df['y'] - temp_test_df['yhat']) / temp_test_df['y'])) * 100\n",
    "print(f'Mean Absolute Percentage Error (MAPE): {mape}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
